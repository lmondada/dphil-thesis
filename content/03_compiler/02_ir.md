+++
title = "A pure internal representation with linear types"
weight = 2
layout = "section"
slug = "sec:ir"
+++

The classical compilation community has found great advantages in
sharing a common standardised IR format. Indeed, whilst the exact
syntax and constructs vary from language to language, and whilst,
at the other end of the compiler stack,
the specific assembly instructions
that are emitted differ between hardare targets,
much of the compiler middleware can be broadly shared between use
cases.
This gave rise to the LLVM @Lattner2004, and more recently,
the MLIR @Lattner_2021 projects, which provide common compiler IRs,
along with all the infrastructure compilers typically require:
IR transformation tooling, translation into hardware-specific
assembly, efficient serialisations, in-memory formats etc.

The idea of adopting LLVM for quantum was championed by QIR @qir, a standard 
introducing quantum primitives into the LLVM IR. 
This was subsequently adopted by many quantum hardware providers for its
superior expressive power compared to circuit-based formats @qirall.
Building on top of QIR, an IR specifically for quantum-classical programs was
proposed in @Hugr, with additional soundness guarantees based among others
on the no-cloning principle of quantum information.
In parallel, projects with similar aims have also emerged @McCaskey2021 @Ittah_2022
that make use of the full MLIR and LLVM toolchain.

Describing the specifics of any one quantum programming language or compiler IR
is beyond our scope and would force us to restrict our considerations
to a narrow subset of the options that are still being actively explored and
developed.
For the purposes of this thesis, it is sufficient to introduce a simplified "toy"
IR that we will call `minIR`. 
It captures all the expressiveness that we require for hybrid programs whilst
remaining sufficiently abstract [^underspec] to be applicable to a variety
of IRs and, by extension, programming languages.
[^underspec]: A critic would say "under-specified".

MinIR is built from statements of the form
```
x, y, ... := op<T1, T2, ...>(a, b, c, ...)
```
to be understood as an operation `op` applied on the inputs `a, b, c, ...`
and producing the outputs `x, y, ...`.
The number of inputs and outputs is determined by the **type signature** of the
operation `op`.
We use the optional `<T1, T2, ...>` syntax to allow for "overloaded" operations:
an operation may be parametrised on some types `T1`, `T2` etc. that will dictate
different type signatures (and their associated semantics) for the operation.
There can be at most one type signature for a given set of types `T1, T2, ...`.

The list of all valid operations along with their
signatures must be defined by the user. A valid set of type signatures could be: 
```python
# A typical quantum gate
h:                  Qubit -> Qubit
# A classical XOR gate on two inputs
xor<Bit, Bit>:      Bit, Bit -> Bit
# The same XOR gate, but with three inputs
xor<Bit, Bit, Bit>: Bit, Bit, Bit -> Bit
# Measurements consume a qubit and produce a bit
measure:            Qubit -> Bit
```
`Bit` and `Qubit` are the defined types. The operations are `h`, `xor` and
`measure`, where `xor` was given two overloaded signatures that can be
distinguished by the type parameters---they are two different operations
that happen to share the same name.

Each variable in the input and output tuples is a _value_ with a fixed _type_
which can always be infered from the type signature that produces and/or consumes
a value.
Throughout, we will omit type parameters whenever it is unambiguous.

Every value must appear exactly once on the left hand side of an IR statement,
as an output.
Values are immutable and represent a piece of data in the computation at one
moment in time.
This IR format is known in compiler speak as single static assignment (SSA) @Rosen1988.
This represents a notable departure from quantum circuits, where
operations are typically thought of as "placed" on a qubit (the "lines" in the
circuit representation) that sits there for the entire duration of the
computation.
In the value semantics of SSA, on the other hand,
qubits only exist in the form of the data they encode: when applying an operation,
the (quantum) data is "given" to the operation and new data is returned.

To make the difference clear, compare the program representations of
the following computation:

{{% columns ratio="1:1" %}}
**Quantum circuit**
```goat
   .---.   .----.
---+ H +---+    +-----------
   '---'   | CX |   .---.
-----------+    +---+ X +---
           '----'   '---'
```
<--->
**minIR (SSA)**<br/>
_in_ : `q0_0`, `q1_0`
_out_ : `q0_2`, `q1_2`
```
q0_1       := h(q0_0)
q0_2, q1_1 := cx(q0_1, q1_0)
q1_2       := x(q1_1)
```
{{% /columns %}}

In value semantics, it becomes much harder to track qubits across their life
span. This has very practical implications: without the convenient naming scheme,
it would for example be non-trivial to count how many qubits are required
in the SSA representation of the computation above.
However, it is a drastically simpler picture from the point of view of the
compiler and the optimiser---hence its popularity in classical compilers.
When operations are defined based on the qubit they act on, the compiler
must carefully track the ordering of these operations: operations on the same
qubit must always be applied in order.
Through multi-qubit gates, this also imposes a (partial) ordering on operations
across different qubits.
Conversely, the fact that two operations, separated in the
computation by a million other operations, will eventually be applied on the
same physical entity is totally irrelevant information to the optimiser.

This is precisely what value semantics abstracts away:
the notion of physical qubit disappears and the ordering of statements
becomes irrelevant.
All that matters is to connect each use of a value (i.e. occurrence as an input
on the right hand side of an IR statement) with its _unique_ definition on
the left hand side of another statement.

In minIR, a program is thus defined by a set of statements, with no explicit
ordering defined between them.
The program is well-defined if

1. every value is defined exactly once (_SSA_),
2. the dataflow graph connecting operations defining values with their uses
is acyclic (_acylicity_) and,
3. it can be successfully typed, i.e. each value can be assigned
a type such that the type signature of each operation in the program is satisfied
(_well-typedness_).

The lack of explicit statement ordering differentiates minIR (and HUGR)
from most classical IRs,
which unless specified otherwise typcially assume that instructions may have
side effects and thus cannot be reordered.
All quantum operations (and the classical operations we are interested in)
are all side-effect free, which significantly simplifies our IR.

### Linear Types and Structured Control Flow
We have studied so far how to express the _data flow_ of a program, i.e. how
outputs of previous computations feed into the inputs of subsequent ones.
An equally essential function of an IR is to capture the _control flow_ of a
program: the order of execution of the program instructions, which is how
an IR can express loops, conditionals, function calls etc.

The most popular---and simplest---way of expressing control flow in classical
IRs is with the introduction of branch statements[^goto].
For instance, LLVM IR provides a conditional branch statement
```llvm
br i1 %cond, label %iftrue, label %iffalse
```
that will jump to the `iftrue` label if `%cond` is true and to the `iffalse`
label otherwise.
[^goto]: You may know this from prehistoric times as the `goto` statement, in
languages such as Fortran, C, and, yes, [even Go](http://golang.org/ref/spec#Goto_statements).

This is a both simple and versatile approach to control flow that can be used
to express any higher level language constructs.
However, in the context of quantum computing, the combination of value-based
semantics, conditional branching and the no-cloning theorem is proving to be
a toxic brew.

Indeed, quantum data introduces an additional condition on the well-formedness
of IR programs: every value that represents a quantum state must not only be
defined _exactly once_, but must also be used _exactly once_.
We call a type that satisfies this constraint a **linear type**[^linear]:

4. every value with a linear type is used exactly once (_linearity_).

In the absence of conditional branching, this is a very simple verification
pass to perform on our IR, the exact converse of checking that each value
is defined exactly once.
[^linear]: The terminology comes from "linear" logic @Girard_1987.
We apologise for slamming additional semantics on an already very
overloaded term.

However, as conditional branching is introduced into the IR, the linearity 
constraint would have to be relaxed to allow for a single use _in each mutually exclusive
branch_ of the program. The following two uses of `b` should be allowed (in pseudo-IR):
```python
b := h(a)
<if cond> c := x(b)
<else>    d := h(b)
```
This is now a much harder invariant to check on the IR and would be extremely
error prone!
Instead, we resort to **structured control flow** to express control flow
at a higher abstraction level and maintain the linearity constraint in its
simplest form.

#### Regions
We introduce a hierarchical nesting of IR blocks that we will call **regions**,
following the MLIR terminology.
Regions delimit a set of instructions that can then be passed to higher order control
flow constructs (functions, conditionals, loops etc.) and be used as their
bodies[^region].
To simplify, we will restrict every value to only be available within its
defining region. 
In particular, regions _do not_ have access to values of regions within which they
are nested.
[^region]: i.e. a region could be used as the body of a function, or the code
within an `if` block.

The values to a region are passed in as arguments to the region, as in
function calls in programming languages.
We require that every region starts with a special `in` statement and ends with
a special `out` statement.
We introduce the following syntax for regions: 
```python
region_name := {
    in: arg1, arg2, ...
    # region body using only values arg1, arg2, ...
    ...
    # and defining values res1, res2, ...
    out: res1, res2, ...
}
```
We can then use `region_name` as any other value in minIR to refer to the region.
Its type will be a special `Region<T1, T2, ...><U1, U2, ...>` type
that is parametrised on the input types and output types of the region.
The only way we can obtain a value of this type is from such a region definition[^llvmblock].
In the following we will simplify the verbose notation and assume `Region`
has a single input `T` and output `U`. This can always be expanded into
multiple arguments (or viewed as a tuple of types).
[^llvmblock]: This is like the label of a block in LLVM IR.
You can also view it as a function pointer, but note that the code that it points
to is always fixed in the IR!

`Region`s allow us to define (very minimal) subroutines!
We define a `call` operation to make use of them:
```python
call<T, U>: Region<T, U>, T -> U
```
We can thus define a region to obtain a `Region` value that we then
pass on to `call` operations to invoke the subroutine.
Finally, the `out` statement of the region designates the values that the
subroutine returns.
These are in turn passed to the outputs of the `call` operation where the subroutine
was invoked. In summary, a subroutine definition and invocation may look like this:
```python
f := {
  in: a, b
  c, d = cx(a, b)
  out: c, d
}

z, w := call(f, x, y)
```
The effect of the call operation to a subroutine is to redirect the control flow 
to the set of operations within the region.
We can obtain the sequence of operations that result from the invocation by
replacing all uses of values output by the region with
the input values to the `call` op, and conversely,
swapping out the values defined by the outputs of the `call` op for the values
in the subroutine in the `out` statement.
In pictures:
{{% columns ratio="1:1" %}}
**The following subroutine invocation**
```goat
  |   |
  |   |          .-----.
  |   |      .---+  in |
  |   |     |    '-+-+-'
  |   |     |      | |
  v   v     |      | |
.-------.   |      v v
| call  |<-'    .------.
'---+---'       |region|
    |           '---+--'
    |               |
    |               v
    |            .-----.
    v            | out |
                 '-----'
```
<--->
**results in the following control flow**
```goat
                 .-----.
  |   |          |  in |
  |   |          '-----'
  |   '--------------.
  '----------------. |
                   | |
.-------.          v v
| call  |       .------.
'-------'       |region|
                '---+--'
    .---------------'
    |                
    |           .-----.
    v           | out |
                '-----'
```
{{% /columns %}}
The left diagram represents the IR, with arrows connecting value definitions
to their uses (the arrow with rounded edges is the `Region` value passed to `call`).
The right diagram on the other hand shows the simplified IR, where the subroutine
was _inlined_, i.e. the `call` operation was replaced with the region as its body.

Notice that because of the precise type signatures we imposed on the `call`
operations and the region definition, the types of the values that are rewired
between the left and right diagrams will always match.


#### Conditionals
Using the same `Region` value, we can model conditional control
flow and loops similarly.
We introduce for this a new boolean type `Bool` that can hold the values `True`
or `False`:
```
ifelse<T, U>: Bool, T, Region<T, U>, Region<T, U> -> U
dowhile<T>: Region<T, (T, Bool)>, T -> T
```
The `ifelse` operation is passed four inputs: a boolean condition, a set of
input values and two `Region`s.
Depending on the value of the boolean condition,
one of the two `Region`s will be evaluated by passing it the input values.
The `dowhile` operation is similar, but instead of being provided a boolean
conditional as input, a `Bool` value can be computed by evaluating the `Region`
passed as input.
At the first iteration, the region passed to the `dowhile` operation is evaluated
on the input value of type `T` .
Each region evaluation returns a new value of `T`.
If the returned boolean condition is true, the `Region` is re-evaluated on the
new value of `T`.
The loop terminates when the returned boolean condition is false.
The outputs of the `dowhile` operation are the values of `T` returned by
the last evaluation of the region.

{{% columns ratio="1:1" %}}
**The `ifelse` operation**
```goat
                     inputs   Bool
                       | |    .
.-----------. if       | |   /  else .-------------.
| if_region +--.       | |  /     .--+ else_region |
'------+-+--'   |      | | |     |   '--+-+--------'
       | |      |      | | |     |      | |
       | |      |      v v v     |      | |
       v v      |   .--------.   |      v v
   .---------.   '->| ifelse |<-'   .---------.
   | if-code |      '---+----'      |else-code|
   '----+----'          |           '----+----'
        |               |                |
        v               |                v
    .--------.          |            .--------.
    |   out  |          v            |   out  |
    '--------'       outputs         '--------'
```
<--->
**The `dowhile` operation**
```goat
            inputs                              
              | |      
              | |           .--------.          
              | |        .--+ region |
              | |       |   '--+-+---'
              | |       |      | |
              v v       |      | |
          .---------.   |      v v
          | dowhile |<-'  .-----------.
          '---+-+---'     | loop-code |
              | |         '--+-+---+--'
              | |            | |   | repeat?
              | |            v v   v 
              | |           .--------.
              v v           | return |
            outputs         '--------'
```
{{% /columns %}}
This approach can be extended to support virtually any control flow primitives,
as required by the available programming language abstractions.
For the purposes of minIR, we will contend ourselves with the three constructs
just introduced.

---

All the concepts introduced here also embed themselves very easily within the
MLIR-based quantum IRs, as well as the (proper) HUGR IR.
In this sense, our toy IR serves as the minimum denominator across IRs and
compiler technologies, so that proposals and contributions we are about to make
can be applied regardless of the underlying technical details.

By waiving goodbye to the circuit model, we have been able to integrate much
of the theory of traditional compiler design and has brought us much closer
to traditional compiler research and the large scale software infrastructure
that is already available.
This naturally gives us access to all the classical optimisation and program
transformation techniques that were developed over decades. Using structured
control flow, we were also able to model linear resources such as qubits
well---by using value semantics and SSA, checking that no-cloning is not
violated is as simple as checking that each linear value is used exactly once.

Finally, this new design is also extremely extensible. Not only does it 
support arbitrary operations, the type system is very flexible, too. There is
dedicated support for linear types, but this does not have to be restricted
to qubits: lists of qubits could be added or even, depending on the target
hardware, higher dimensional qudits, continuous variable quantum data, etc.
