+++ title = "The data structure" layout = "section" weight = 3 slug = "sec:persistent-ds" +++

We now present a data structure _inspired_ by equality saturation, but for arbitrary graph rewriting. Rather than maintaining equivalence relations between terms, as done in term graphs, we maintain equivalence relations between graph vertices. Our data structure stores in fact the set of all applied rewrites---the main subject of this section is to show how all operations of interest on this data structure can be implemented efficiently.


The persistent graph rewriting data structure is given by a set $\mathcal{D}$ of _edits_ $\delta = (G_R, V^-, \mu) \in \mathcal{D}$, with - vertex deletion set $V^- \subseteq V(\mathcal{D} \smallsetminus \delta)$ and - gluing relation $\mu: V^- \rightharpoonup V(G_R)$.

We have extended the $V(\cdot)$ notation to $\mathcal{D}$ by defining them by the union of all vertex resp. edge sets of replacement graphs in $\mathcal{D}$. We will similarly use $V(\delta)$ to denote the set of vertices in the replacement graph of a rewrite $\delta$.

Edits are very similar to rewrites as defined in Definition 5.1, but differ in that their definition does not specify a graph $G$ they apply to: the vertices of $V^-$ do not belong to a single graph, but rather to the collection of all replacement graphs in $\mathcal{D}$. We will see below how a graph $G$ can be constructed such that an edit $\delta \in \mathcal{D}$ is indeed a valid rewrite on $G$.

Importantly, we assume that all vertices $v \in V(\mathcal{D})$ are distinct, i.e. there is a unique replacement graph $G_R$ in an edit of $\mathcal{D}$ such that $v \in V(G_R)$. We write it as $origin(v) = G_R$. The parents of an edit $\delta = (G_R, V^-, \mu)$ are $$parents(\delta) = \left\{ \delta_p \in \mathcal{D} \mid V^- \cap V(\delta_p) \neq \varnothing \right\},$$ i.e. the set of edits whose vertices appear in the deletion set $V^-$ of $\delta$. Conversely, we define the children of $\delta$ as the set of edits whose parents include $\delta$ $$children(\delta) = \left\{\delta_c \in \mathcal{D} \mid \delta \in parents(\delta_c)\right\}.$$

#### Merges, confluent persistence and edit creation

As noted above, edits $\delta$ in $\mathcal{D}$ are not defined with respect to a single graph $G$: the vertex deletion set $V^-$ as well as the gluing relation $\mu$ act on $V(\mathcal{D})$, hence different vertices might belong to different edits in $\mathcal{D}$.

This is how confluent persistence is achieved. Rather than handling merges of versions of the data structure explicitly, we will allow rewrites to be applied not only on previous versions of the data, but also on collections of several versions---equivalent to creating explicitly a merged version of the graph followed by the desired rewriet. The relation between edits in $\mathcal{D}$ given by the sets $parents(\delta)$ and $children(\delta)$ define the edit history of the confluently persistent data structure---which is only well-defined if the parent-child relationships are acylic.

We can enforce acyclicity by restricting how $\mathcal{D}$ can be constructed and modified. Specifically, we introduce the procedures ```python def create_empty() -> Set[Edit]:     return set()

def add_edit(     edits: Set[Edit],     replacement_graph: Graph     deletion_set: Set[V],     gluing_relation: EquivalenceRelation[V] ) -> Set[Edit]:     new_edit = (         replacement_graph,         deletion_set,         gluing_relation     )     parents = parents(new_edit)     assert(issubset(parents, edits))     assert(are_compatible(parents))

    edits = union(edits, {new_edit}) ``` that respectively returns an empty $\mathcal{D} = \{\}$ and adds an edit $\delta$ to $\mathcal{D}$. The `are_compatible` function is described and defined below. All other functions (`issubset` and `parents`) have the obvious definition.

Crucially, by the definition of $parents$, only edits may be added to $\mathcal{D}$ if all vertices they refer to in the vertex deletion set $V^-$ belong to graphs that are already present in $\mathcal{D}$. It is thus impossible to create a cyclic parent-child relationship as child edits must always be added to $\mathcal{D}$ after their parents.

We say that $\mathcal{D}$ is valid if it can be constructed from a single call to `create_empty`, followed by a sequence of calls to `add_edit`. This is equivalent to requiring that _i)_ the parent-child relationship is acylic and _ii)_ the parents of every edit satisfy `are_compatible`. For the remainder of this chapter, we will always assume that $\mathcal{D}$ is valid. As a consequence, it also follows that the set $ancestors(\delta)$ is always a set of compatible edits.

#### Compatible edits A further requirement when adding an edit to $\mathcal{D}$ using the `add_edit` procedure is that all parents must be _compatible_. Assuming the parent-child relationship is acylic, we can define recursively $$ancestors(\delta) = \{\,\delta\,\}\ \cup\ \bigcup_{\delta_p \in parents(\delta)} ancestors(\delta_p).$$ A set of edits $D \subseteq \mathcal{D}$ are compatible if all vertex deletion sets $V^-$ for all ancestors of $\delta \in D$ are disjoint. That is, writing $$A = \{ a \in ancestors(d) \mid d \in D \}$$ for the set of ancestors of edits in $D$, we require that all sets $$\{V^- \mid (G_R, V^-, \mu) \in A\}$$ are disjoint.


As pseudocode, this can be implemented straightforwardly as: ```python def are_compatible(edits: Set[Edit]) -> bool:     all_ancestors = set({         a for a in ancestors(d) for d in edits     })     deleted_vertices = set()     for d in all_ancestors:         for v in deletion_set(d):             if v in deleted_vertices:                 return False             deleted_vertices.add(v)     return True ``` The runtime is $O(D_A \log D_A)$, where $D_A$ is the sum of the sizes of all vertex deletion sets of the ancestors of the edits in $D$. The $\log$ factor can typically be removed if the vertices $v$ span a contiguous integer range or by using a hash function. Alternatively, the $\log$ factor can also be reduced by using separate sets to track deleted vertices of each edit.

#### Edits are rewrites on the flattened history

We have so far explored how edits can be added to $\mathcal{D}$, as well as when they are compatible. However, until we have established that adding edits to $\mathcal{D}$ is _in some sense_ equivalent to applying rewrites on a graph, it is hard to see how the data structure $\mathcal{D}$ would be useable for graph rewriting. This is precisely our next point.

Consider a set of compatible edits $D \subseteq \mathcal{D}$ and let $$A = \{ a \in ancestors(d) \mid d \in D \}$$ be the set of ancestors of edits in $D$. All edits in $A$ must be compatible. Define a topological ordering $(\delta_1, \ldots, \delta_k)$ of the edits in $A$, i.e. if $\delta_i$ is a parent of $\delta_j$ then $i < j$.

{{< proposition number="5.2" >}} There are graphs $G_0, \ldots, G_k$ such that for all $1 \leqslant i \leqslant k$, the edit $\delta_i$ defines a valid rewrite $r_i$ on $G_{i-1}$ and $G_i = r_i(G_{i-1})$. {{< /proposition >}}

{{% proof %}} Define the empty graph $G_0 = \varnothing$. The edit $\delta_1$ has no parent and thus must have an emtpy vertex deletion set and gluing relation. It is thus a valid rewrite $r_1$ on $G_0$.

We can repeat this construction inductively for graphs $G_2, \ldots, G_k$ if we show for $2 \leqslant i \leqslant k$ that the $i$-th edit $\delta_i$ defines a valid rewrite $r_i$ on $G_{i-1}$. The set of vertices in $G_{i-1}$ is the union of all vertices in the replacement graph of $\delta_1, \ldots, \delta_{i-1}$ minus their vertex deletion sets $$V(G_{i-1}) = \left(\bigcup_{1 \leqslant j < i} V(\delta_j)\right) \setminus \left(\bigcup_{1 \leqslant j < i} V^-_j\right),$$ where $V^-_j$ is the vertex deletion set of $\delta_j$.

Now, by definition of the edit $\delta_i$, $$V^-_i \subseteq \bigcup_{1 \leqslant j < i} V(\delta_j).$$ On the other hand, because of the compatibility of all edits in $A$, we know that $V^-_i \cap V^-_j =\varnothing$ for all $1 \leqslant j < i$. It thus follows $V^-_i \subseteq V(G_{i-1})$. It follows that $\delta_i$ is indeed a valid rewrite of $G_{i-1}$, and thus $r_i$ and $G_i$ are well-defined. {{% /proof %}}

After this warm-up, we now show that the graph $G_k$ thus obtained can be uniquely from $D \subseteq \mathcal{D}$, with an explicit procedure on how to construct it! {{< proposition number="5.3" >}} The graph $G_k$ obtained by applying the set of compatible rewrites $A$ in order on the empty graph is independent of the topological ordering chosen. Given the set of rewrites $D \subseteq \mathcal{D}$, the procedure `flatten_history` returns $G$ in time $$O(m + n)$$ where $n$ and $m$ are the total number of vertices and edges across all replacement graphs in $A$. {{< /proposition >}}

Here is the definition of `flatten_history`: ```python {.numbered} def flatten_history(edits: Set[Edit]) -> Graph:     all_ancestors = set({         a for a in ancestors(d) for d in edits     })     graph = Graph()     for a in toposort(all_ancestors):         add_graph(graph, replacement_graph(a))         for (del_v, repl_v) in gluing_relation(a):             move_edges(graph, repl_v, del_v)         for v in deletion_set(a):             remove_vertex(graph, v)     return graph ``` `toposort` is a function that returns a topological ordering of the rewrites in $A$ according to the parent-child rewrite relation, `add_graph` inserts the graph passed as second argument into the graph passed as first argument, `remove_vertex` removes the vertex along with all incident edges from the graph and `move_edges` moves all edges of the second vertex to the first vertex.

{{% proof %}} **Correctness of `flatten_history`.**&emsp; It is easy to see that if the graph $G$ that is obtained from applying the rewrites in order is independent of the choice of the toplogical ordering, then `flatten_history` is a correct implementation of the procedure, as it applies one rewrite at a time, in topological order.

**Rewrite order invariance.**&emsp; Consider two rewrites $\delta_1$ and $\delta_2$ in $A$ such that neither is an ancestor of the other. Let $$A_{pre}  = ancestors(\delta_1) \cup ancestors(\delta_2) \subseteq A$$ and proceed by induction over $A_{pre}$: assume the graph $G_{pre}$ obtained by applying the rewrites in $A_{pre}$ is invariant on the choice of the topological ordering of $A_{pre}$. Clearly this is true for $A_{pre} = \varnothing$. All that remains to be shown is that $G_{post}$ obtained by applying first $\delta_1$ then $\delta_2$ on $G_{pre}$ is equal to $G_{post}'$, obtained by applying the same rewrites in the reverse order on $G_{pre}$.

The vertex sets $V^-_1$ and $V^-_2$ of $\delta_1$ and $\delta_2$ must be disjoint because $\delta_1, \delta_2 \in A$ and hence are compatible. Furthermore, the replacement graphs (by definition of the rewrites) and the gluing relations of $\delta_1$ and $\delta_2$ (by rewrite compatibility) cannot contain vertices in $V^-_1 \cup V^-_2$. It follows that the order in which vertices of $V^-_1 \cup V^-_2$ are removed from $G_{pre}$ does not affect the graph $G_{post}$. Furthermore, vertex merging is a commutative operation, and so is disjoint graph addition. It follows $G_{post} = G_{post}'$ and hence the result.

**Runtime.**&emsp; In total $n$ vertices and $m$ edges will be added to `graph` by `add_graph` on line 7. As a result at most $n$ vertices can ever be deleted by line 11. Finally, while a naive implementation of `move_edges` of line 9 might result in the same edge being moved many times, all edge moves can be cached and only executed once at the end: notice that every time edges are moved away from a vertex, that vertex is subsequently removed from the graph. Instead of removing the vertex, keep it "hidden", with a link to the vertex that the edges should be moved to. Once all graph operations are completed, traverse all hidden vertices and follow the links to the vertices that the edges should be moved to. This can be done in $O(n)$ time. Then move all edges to the correct vertex, in time $O(m)$, and delete the hidden vertices. {{% /proof %}}

Now instead of exploring the space of all graphs $\mathcal{G}$ reachable by repeatedly applying rewrites, we can explore the rewrite space by adding edits to $\mathcal{D}$. If $\mathcal{G}'$ is the set of all graphs returned by `flatten_history` on subsets of compatible edits in $\mathcal{D}$

$$\begin{aligned}\mathcal{G}' = \{\ &\texttt{flatten\_history}(D) \mid\\&  D \subseteq \mathcal{D}: D \text{ contains compatible edits}\},\end{aligned}$$

then Propositions 5.2 and 5.3 combined guarantee that $\mathcal{G}' \subseteq \mathcal{G}$. We conclude by showing that indeed any graph in $\mathcal{G}$ is also in $\mathcal{G}'$, and hence $\mathcal{G} = \mathcal{G}'$.

{{< proposition number="5.4" >}} Let $G$ be a graph and $D \subseteq \mathcal{D}$ be a set of compatible edits such that `flatten_history(D)` $= G$. Then any rewrite $r$ that can be applied on $G$ defines an edit $\delta$ that can be added to $\mathcal{D}$. {{< /proposition >}} {{% proof %}} We recall that a rewrite $r = (G_R, V^-, \mu)$ defines an edit $\delta = (G_R, V^-, \mu)$ that can be added to $\mathcal{D}$ if - $V^- \subseteq V(\mathcal{D})$, - $parents(\delta) \subseteq \mathcal{D}$, and - all rewrites in $parents(\delta)$ are compatible.

By the rewrite definition, $V^- \subseteq V(G)$. It follows in particular that $$V^- \subseteq \bigcup_{\delta' \in D} V(\delta'),$$ and thus $V^- \subseteq V(\mathcal{D})$, as well as $parents(\delta) \subseteq D \subseteq \mathcal{D}$. This proves all three conditions. {{% /proof %}}

Initialise $\mathcal{D}$ with a single root rewrite that rewrites the empty graph to an input graph $\varnothing \rightarrow G$: ```python def create_from_graph(G: Graph) -> D:     d = create_empty()     d = add_edit(d,         replacement_graph = G,         deletion_set = set(),         gluing_relation = {}     )     return d ``` Clearly, `flatten_history(D)` $=G$ for $D =$ `create_from_graph(G)`. Thus, applying Proposition 5.4 repeatedly, if we have a sequence $(r_1, \ldots, r_k)$ of valid rewrites that can be applied on $G$, then the sequence of edits $(\delta_1, \ldots, \delta_k)$ that it defines can also be added to $D$ in this order---call the resulting set of edits $D'$. As we have further seen in Propositions 5.2 and 5.3, the graph $G_k$ that is obtained as a result of the rewrites is the same graph returned by `flatten_history` called on $D'$.

In other words, we conclude that exploring the rewrite space on $G$ is fully equivalent to exploring the space of valid edits on `create_from_graph(G)`.

#### Traversing the data structure for pattern matching

Suppose you are given a GTS and would like to use $\mathcal{D}$ to perform graph rewriting on some input graph $G$. We already know from our results above that whatever rewrites we would apply on $G$ can be added as edits to $\mathcal{D}$. We also know that the graphs $G'$ resulting from rewrites can equivalently be recovered from $\mathcal{D}$ using `flatten_history` on a set of compatible edits $D \subseteq \mathcal{D}$.

We are only missing one piece: how do we traverse the search space? In other words, how do we find all applicable rewrites on all graphs within $\mathcal{D}$? A naive solution would iterate over _all_ subsets of $D \subseteq \mathcal{D}$, check whether they form a compatible set of edits, compute `flatten_history` if they do, and finally run pattern matching on the obtained graph. We can do better.

The idea is to traverse the set of edits in $\mathcal{D}$ using the gluing relations $\mu$ that connect vertices between edits. Define the inverse relation $\mu^{-1}$ on all of $V(\mathcal{D}) \to \mathcal{P}(V(\mathcal{D}))$ as follows: $$\begin{aligned}\mu^{-1}(v) = \{&w \in V(\mathcal{D})\mid\\&  \text{there exist } \delta \in \mathcal{D}, v \in V^-(\delta): \mu(w) = v\},\end{aligned}$$ where $\mu$ refers to the gluing relation of the edit $\delta$. This can be used to define the procedure `equivalent_vertices`: given a vertex $v$ and a set of edits $D \subseteq \mathcal{D}$, it applies $\mu^{-1}(v)$ recursively and filters it to only include vertices whose owner is compatible with $D$. The set of vertices returned are vertices of descendant edits of $owner(v)$.

```python def equivalent_vertices(     v: Vertex, edits: Set[Edit] ) -> Set[Vertex]:     all_vertices = set({v})     for w in mu_inv(v):         new_edits = union(edits, {owner(w)})         if are_compatible(new_edits):             all_vertices = union(all_vertices,                 equivalent_vertices(w, new_edits)             )     return all_vertices ```

Whilst it looks as though `equivalent_vertices` does not depend on $\mathcal{D}$, it does so through the use of the function calls to `mu_inv`.

We use `equivalent_vertices` to repeatedly extend a set of _pinned_ vertices $Pin \subseteq V(\mathcal{D})$. A set of pinned vertices must satisfy two properties: - the set $D = \{owner(v) \mid v \in Pin\}$ is a set of compatible edits, - there is no vertex $v \in Pin$ and edit $\delta \in D$ such that $v \in V^-(\delta)$.

As a result, calling $G$ the flattened history of $D$, it always holds that $Pin \subseteq V(G)$. Furthermore, if $G(Pin) \subseteq G$ is the subgraph of $G$ induced by $Pin$, then for any set of pinned vertices $Pin' \supseteq Pin$, we have $G(Pin) \subseteq G'(Pin')$ where $G'$ is the flattened history of the edits $D'$ of $Pin'$. This follows directly from the second property above and the definition of `flatten_history`.

This gives us a the following simple pseudo-procedure for pattern matching: 1. Start with a single pinned vertex $Pin = \{v\}$. 2. Construct partial embeddings $P \rightharpoonup G(Pin)$ for patterns $P$. 3. Pick a new vertex $v$ in the flattened history $G$ of $Pin$ but not in $G(Pin)$ (that we would like to extend the domain of definition of our pattern embeddings to). 4. For all vertices $v'$ in `equivalent_vertices(v, D)`, build new pinned vertex sets $Pin' = Pin \cup \{v'\}$, filter out the sets $Pin'$ that are not valid pinned vertex sets. 5. Repeat steps 2--4 until all pattern embeddings have been found.

Step 1 is straightforward---notice that pattern matching must be started at a vertex in $V(\mathcal{D})$, so finding all patterns will require iterating over all choices of $v$. The pattern embeddings are constructed over iterations of step 2: each iteration can be seen as one step of the pattern matcher---for instance as presented in {{% reflink "chap:matching" %}}---extending the pattern embeddings that can be extended and discarding those that cannot. If all possible pattern embeddings have been discarded, then matching can be aborted for that $Pin$ set.

How step 3 should be implemented depends on the types of graphs and patterns that are matched on. It is particularly simple in the case of minIR graphs with only linear values, i.e. hypergraphs with hyperedges that have directed, ordered endpoints and vertices that are incident to exactly one incoming and one outgoing edge. In that case, $v$ can always be chosen in such way as to ensure progress on the next iteration of step 2, i.e. the domain of definition of at least one partial pattern embedding $P \hookrightarrow G(Pin)$ will be extended by one vertex. The info box below explains this case in more detail.

Step 4 produces all possible extensions of $Pin$ to pinned vertex sets $Pin'$ that include a descendant $v'$ of $v$ (or $v$ itself). All vertices returned by `equivalent_vertices` will be in edits compatible with $D$, so to check that $Pin'$ is a valid pinned vertex set, we only need to check the second property of pinned vertices. Let $P$ be a pattern, let $\mathcal{A}$ be the set of all $Pin$ sets under consideration and let $D$ be the set of edits of vertices in $Pin \in \mathcal{A}$. Step 4 increments the sizes of all pinned vertex sets in $\mathcal{A}$ whilst maintaining the following invariant.

**Invariant for step 4.**&emsp; If there is a superset $D' \supseteq D$ of compatible edits such that $P$ embeds in $G'$, the flattened history of $D'$, then there is a set of pinned vertices $Pin \in \mathcal{A}$ and a superset $Pin' \supseteq Pin$ of vertices such that $P$ embeds in $G(Pin')$.


Finally, step 5 ensures the process is repeated until for all partial pattern embeddings, either the domain of definition is complete, or the embedding of $P$ is not possible. Given that step 4 increments the size of $Pin$ sets at each iteration, this will terminate as long as the vertex picking strategy of step 3 selects vertices that allow to extend (or refute) the partial pattern embeddings constructed and extended in step 2. This is satisfied for example in the case of linear minIR graphs, as explained in the info box.

{{% hint "info" %}} **Choosing the next vertex to pin in linear minIR (step 3).** &emsp; Assuming patterns are connected, for any partial pattern embedding $P \hookrightarrow G(Pin)$ there is an edge $e_P \in E(P)$ with no image in $G(Pin)$ but such that at least one of the endvertex $v_P$ of $e_P$ has an image $v_G$ in $Pin$---say, $e_P$ is the outgoing edge of $v_P$. Let $v'_P$ be an endvertex of $e_P$ in $P$ that has no image in $G(Pin)$---and say, it is the $i$-th outgoing endvertex of $e_P$ in $P$.

Then $v_P$ uniquely identifies an edge $e_G$ in $G$, the flattened history of $Pin$---the unique outgoing edge of $v_G$---which, in turn, uniquely identifies a vertex $v'_G \in V(G)$---the $i$-th outgoing endvertex of $e_G$. By choosing $v'_G$ in step 3, step 4 will create pinned vertex sets that include all possible vertices equivalent to $v_G'$, which are all vertices that $v_G$ might be connected to through its outgoing edge[^realisethis]. The next iteration of step 2 will then be able to either extend the partial pattern embedding to $v_P$ or conclude that an embedding of $P$ is not possible. {{% /hint %}} [^realisethis]: To realise this, notice that all vertices equivalent to $v_G'$ are vertices that will be merged with $v_G'$. Hence they will all be attached to the outgoing edge of $v_G$ at its $i$-th outgoing endvertex.

Using the approach we have just sketched, pattern matching can thus be performed on the persistent data structure $\mathcal{D}$. The runtime of steps 2 and 3 depend on the type of graphs and patterns that are matched on---these are however typical problems that appear in most instances of pattern matching, independently of the data structure $\mathcal{D}$ used here. A concrete approach to pattern matching and results for the graph types of interest to quantum compilation are presented in {{% reflink "chap:matching" %}}. TODO: Appendix B further discusses how pattern matching and persistent rewriting can be combined and proposes a compilation platform that leverages both.

The runtime of the remaining steps will depend on the number of edits in $\mathcal{D}$ (`equivalent_vertices` depends on `are_compatible`, which runs in runtime linear in the number of ancestors), and also the number of equivalent vertices that successive rounds of step 4 will produce. Rather than providing very loose worst case asymptotic bounds or making stringent assumptions on properties of the GTS and of the pattern matching algorithm used, the next section proposes an analysis of the complexity of persistent rewriting through the prism of the overall size of the search space that is explored. 